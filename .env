# .env file - Environment configuration for AI Concierge

# ===========================================
# LOCAL LLM CONFIGURATION
# ===========================================
# Path to your local Llama model (GGUF format)
LOCAL_MODEL_PATH="/mnt/g/Wissam/ByteBricksTestWissam/app/models/Llama-3.2-3B-Instruct-IQ4_XS.gguf"

# ===========================================
# EXTERNAL LLM PROVIDERS (Optional)
# ===========================================
# OpenAI API (paid - uncomment if you want to use GPT models)
# OPENAI_API_KEY=sk-your_openai_key_here

# Hugging Face API (free tier available - for cloud inference only)
# HUGGINGFACE_API_TOKEN=hf_your_huggingface_token_here

# ===========================================
# SECURITY SETTINGS
# ===========================================
# Secret key for JWT tokens (CHANGE THIS IN PRODUCTION!)
SECRET_KEY="abc123"

# ===========================================
# APPLICATION SETTINGS
# ===========================================
# API version prefix
API_V1_STR="/api/v1"

# Project name
PROJECT_NAME="AI Concierge"

# Knowledge base path
KNOWLEDGE_BASE_PATH="/mnt/g/Wissam/ByteBricksTestWissam/data/knowledge_base.json"

# ===========================================
# DATABASE SETTINGS (if needed)
# ===========================================
# DATABASE_URL=sqlite:///./app.db

# ===========================================
# CORS SETTINGS (if needed for frontend)
# ===========================================
# ALLOWED_HOSTS=localhost,127.0.0.1,your-domain.com